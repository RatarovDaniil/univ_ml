{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data discription\n",
    "\n",
    "1. __FIRMCOST__ - The measure of the firm’s risk management cost effectiveness, defined as total property and casualty premiums and uninsured losses as a percentage of total assets.\n",
    "\n",
    "1. __ASSUME__ - Per occurrence retention amount as a percentage of total assets.\n",
    "\n",
    "1. __SIZELOG__ - Logarithm of total assets.\n",
    "\n",
    "1. __INDCOST__ - A measure of the firm’s industry risk.\n",
    "\n",
    "1. __CENTRAL__ - A measure of the importance of the local managers in choosing the amount of risk to be retained.\n",
    "\n",
    "1. __SOPH__ - A measure of the degree of importance in using analytical tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(df, col_names):\n",
    "    '''\n",
    "        compute correlation matrix\n",
    "    '''\n",
    "    rs = np.random.RandomState(0)\n",
    "    df = pd.DataFrame(rs.rand(len(col_names), len(col_names)), columns=col_names)\n",
    "    corr = df.corr()\n",
    "    corr = corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n",
    "    \n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to RiskSurvey data\n",
    "PATH_TO_DATA = 'regression-data/data-actuarial/RiskSurvey.csv'\n",
    "\n",
    "# creating dataframe\n",
    "df = pd.read_csv(PATH_TO_DATA)\n",
    "df = df.drop('CAP', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRMCOST</th>\n",
       "      <th>ASSUME</th>\n",
       "      <th>SIZELOG</th>\n",
       "      <th>INDCOST</th>\n",
       "      <th>CENTRAL</th>\n",
       "      <th>SOPH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>9.55</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.31</td>\n",
       "      <td>0.89</td>\n",
       "      <td>8.04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.07</td>\n",
       "      <td>1.67</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.94</td>\n",
       "      <td>1.21</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.35</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7.74</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIRMCOST  ASSUME  SIZELOG  INDCOST  CENTRAL  SOPH\n",
       "0      3.29    0.29     9.55     0.32        1    25\n",
       "1      9.31    0.89     8.04     0.33        2    24\n",
       "2      4.07    1.67     7.90     0.34        2    15\n",
       "3      6.94    1.21     8.10     0.34        1    16\n",
       "4      5.35    0.28     7.74     0.09        3    18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRMCOST</th>\n",
       "      <th>ASSUME</th>\n",
       "      <th>SIZELOG</th>\n",
       "      <th>INDCOST</th>\n",
       "      <th>CENTRAL</th>\n",
       "      <th>SOPH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.973288</td>\n",
       "      <td>2.573562</td>\n",
       "      <td>8.331918</td>\n",
       "      <td>0.418356</td>\n",
       "      <td>2.246575</td>\n",
       "      <td>21.191781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.158611</td>\n",
       "      <td>8.444978</td>\n",
       "      <td>0.963378</td>\n",
       "      <td>0.216243</td>\n",
       "      <td>1.255884</td>\n",
       "      <td>5.303713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.270000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.510000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.080000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.710000</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>8.950000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97.550003</td>\n",
       "      <td>61.820000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FIRMCOST     ASSUME    SIZELOG    INDCOST    CENTRAL       SOPH\n",
       "count  73.000000  73.000000  73.000000  73.000000  73.000000  73.000000\n",
       "mean   10.973288   2.573562   8.331918   0.418356   2.246575  21.191781\n",
       "std    16.158611   8.444978   0.963378   0.216243   1.255884   5.303713\n",
       "min     0.200000   0.000000   5.270000   0.090000   1.000000   5.000000\n",
       "25%     3.510000   0.240000   7.650000   0.330000   1.000000  18.000000\n",
       "50%     6.080000   0.510000   8.270000   0.340000   2.000000  23.000000\n",
       "75%    12.710000   1.670000   8.950000   0.500000   3.000000  25.000000\n",
       "max    97.550003  61.820000  10.600000   1.220000   5.000000  31.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data description\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show correlation between predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col0 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col1 {\n",
       "            background-color:  #ee8468;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col2 {\n",
       "            background-color:  #dadce0;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col3 {\n",
       "            background-color:  #89acfd;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col4 {\n",
       "            background-color:  #b2ccfb;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col5 {\n",
       "            background-color:  #da5a49;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col0 {\n",
       "            background-color:  #f59f80;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col1 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col2 {\n",
       "            background-color:  #9abbff;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col4 {\n",
       "            background-color:  #97b8ff;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col5 {\n",
       "            background-color:  #ee8468;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col0 {\n",
       "            background-color:  #f5c4ac;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col1 {\n",
       "            background-color:  #f2cab5;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col2 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col3 {\n",
       "            background-color:  #dfdbd9;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col4 {\n",
       "            background-color:  #f59c7d;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col5 {\n",
       "            background-color:  #bbd1f8;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col2 {\n",
       "            background-color:  #5f7fe8;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col3 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col4 {\n",
       "            background-color:  #f0cdbb;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col5 {\n",
       "            background-color:  #3c4ec2;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col0 {\n",
       "            background-color:  #88abfd;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col1 {\n",
       "            background-color:  #afcafc;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col2 {\n",
       "            background-color:  #efcfbf;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col3 {\n",
       "            background-color:  #f5c4ac;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col4 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col0 {\n",
       "            background-color:  #e16751;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col1 {\n",
       "            background-color:  #ea7b60;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col3 {\n",
       "            background-color:  #5977e3;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col5 {\n",
       "            background-color:  #b40426;\n",
       "        }</style>  \n",
       "<table id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >FIRMCOST</th> \n",
       "        <th class=\"col_heading level0 col1\" >ASSUME</th> \n",
       "        <th class=\"col_heading level0 col2\" >SIZELOG</th> \n",
       "        <th class=\"col_heading level0 col3\" >INDCOST</th> \n",
       "        <th class=\"col_heading level0 col4\" >CENTRAL</th> \n",
       "        <th class=\"col_heading level0 col5\" >SOPH</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73level0_row0\" class=\"row_heading level0 row0\" >FIRMCOST</th> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col0\" class=\"data row0 col0\" >1</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col1\" class=\"data row0 col1\" >0.66</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col2\" class=\"data row0 col2\" >0.52</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col3\" class=\"data row0 col3\" >-0.3</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col4\" class=\"data row0 col4\" >0.0099</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row0_col5\" class=\"data row0 col5\" >0.82</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73level0_row1\" class=\"row_heading level0 row1\" >ASSUME</th> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col0\" class=\"data row1 col0\" >0.66</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col1\" class=\"data row1 col1\" >1</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col2\" class=\"data row1 col2\" >0.33</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col3\" class=\"data row1 col3\" >-0.7</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col4\" class=\"data row1 col4\" >-0.11</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row1_col5\" class=\"data row1 col5\" >0.69</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73level0_row2\" class=\"row_heading level0 row2\" >SIZELOG</th> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col0\" class=\"data row2 col0\" >0.52</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col1\" class=\"data row2 col1\" >0.33</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col2\" class=\"data row2 col2\" >1</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col3\" class=\"data row2 col3\" >0.16</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col4\" class=\"data row2 col4\" >0.6</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row2_col5\" class=\"data row2 col5\" >0.052</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73level0_row3\" class=\"row_heading level0 row3\" >INDCOST</th> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col0\" class=\"data row3 col0\" >-0.3</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col1\" class=\"data row3 col1\" >-0.7</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col2\" class=\"data row3 col2\" >0.16</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col3\" class=\"data row3 col3\" >1</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col4\" class=\"data row3 col4\" >0.37</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row3_col5\" class=\"data row3 col5\" >-0.53</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73level0_row4\" class=\"row_heading level0 row4\" >CENTRAL</th> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col0\" class=\"data row4 col0\" >0.0099</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col1\" class=\"data row4 col1\" >-0.11</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col2\" class=\"data row4 col2\" >0.6</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col3\" class=\"data row4 col3\" >0.37</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col4\" class=\"data row4 col4\" >1</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row4_col5\" class=\"data row4 col5\" >-0.54</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73level0_row5\" class=\"row_heading level0 row5\" >SOPH</th> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col0\" class=\"data row5 col0\" >0.82</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col1\" class=\"data row5 col1\" >0.69</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col2\" class=\"data row5 col2\" >0.052</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col3\" class=\"data row5 col3\" >-0.53</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col4\" class=\"data row5 col4\" >-0.54</td> \n",
       "        <td id=\"T_d0d92bc2_561c_11e9_a2b8_3c77e641ce73row5_col5\" class=\"data row5 col5\" >1</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2a8000b208>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build correlation matrix of predictors\n",
    "corr(df.loc[:, 'FIRMCOST':'SOPH'], ['FIRMCOST', 'ASSUME', 'SIZELOG', 'INDCOST', 'CENTRAL', 'SOPH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.65692943e-01, -2.06567267e+00,  3.21444851e+01, -2.46195547e-02,\n",
       "       -1.91112242e-01,  1.82712436e+01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_linear_model(df):\n",
    "    input_matrix = df.copy()\n",
    "    input_matrix['INTERCEPT'] = pd.Series(1, index=input_matrix.index)\n",
    "    \n",
    "    X = input_matrix.loc[:, 'ASSUME':'INTERCEPT'].values\n",
    "    y = input_matrix['FIRMCOST'].values\n",
    "    \n",
    "    coefs = np.dot(np.dot(np.linalg.inv(np.dot(X.transpose(), X)), \n",
    "                          X.transpose()), y)\n",
    "    \n",
    "    return coefs\n",
    "\n",
    "# split dataset on train and test 60:40, due to low number of examples\n",
    "X_train, X_test = df[:40], df[40:]\n",
    "# compute coefficient for linear model\n",
    "coefs = fit_linear_model(X_train)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.160693</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>-5.000693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.355577</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>-3.995577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5.532433</td>\n",
       "      <td>7.830000</td>\n",
       "      <td>2.297567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>9.434665</td>\n",
       "      <td>5.090000</td>\n",
       "      <td>-4.344665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-4.519594</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.719594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.408182</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>1.441818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9.943768</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>-9.183768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.365878</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>0.344122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>27.372334</td>\n",
       "      <td>17.530001</td>\n",
       "      <td>-9.842334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.918854</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.081146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.524667</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>-3.464667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4.203710</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>-3.273710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>12.420589</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-2.420589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>14.960786</td>\n",
       "      <td>5.820000</td>\n",
       "      <td>-9.140786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.799707</td>\n",
       "      <td>9.130000</td>\n",
       "      <td>3.330293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>14.295559</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-5.295559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>28.505357</td>\n",
       "      <td>12.610000</td>\n",
       "      <td>-15.895358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5.473248</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>-3.323248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>9.991330</td>\n",
       "      <td>22.219999</td>\n",
       "      <td>12.228669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>9.269259</td>\n",
       "      <td>12.710000</td>\n",
       "      <td>3.440741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>14.418950</td>\n",
       "      <td>15.970000</td>\n",
       "      <td>1.551050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.914935</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>-1.594934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>7.990755</td>\n",
       "      <td>8.490000</td>\n",
       "      <td>0.499245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>13.591023</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>-8.341023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>23.189775</td>\n",
       "      <td>18.330000</td>\n",
       "      <td>-4.859775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>12.571876</td>\n",
       "      <td>21.719999</td>\n",
       "      <td>9.148123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.913659</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-5.513659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>9.121543</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>-5.421543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>11.491456</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.508544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>23.757871</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-5.757871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>8.911315</td>\n",
       "      <td>29.120001</td>\n",
       "      <td>20.208686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>13.261827</td>\n",
       "      <td>79.300003</td>\n",
       "      <td>66.038176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>33.217764</td>\n",
       "      <td>13.570000</td>\n",
       "      <td>-19.647764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictions     actual   residual\n",
       "40     7.160693   2.160000  -5.000693\n",
       "41     4.355577   0.360000  -3.995577\n",
       "42     5.532433   7.830000   2.297567\n",
       "43     9.434665   5.090000  -4.344665\n",
       "44    -4.519594   0.200000   4.719594\n",
       "45     7.408182   8.850000   1.441818\n",
       "46     9.943768   0.760000  -9.183768\n",
       "47     5.365878   5.710000   0.344122\n",
       "48    27.372334  17.530001  -9.842334\n",
       "49     5.918854  14.000000   8.081146\n",
       "50     5.524667   2.060000  -3.464667\n",
       "51     4.203710   0.930000  -3.273710\n",
       "52    12.420589  10.000000  -2.420589\n",
       "53    14.960786   5.820000  -9.140786\n",
       "54     5.799707   9.130000   3.330293\n",
       "55    14.295559   9.000000  -5.295559\n",
       "56    28.505357  12.610000 -15.895358\n",
       "57     5.473248   2.150000  -3.323248\n",
       "58     9.991330  22.219999  12.228669\n",
       "59     9.269259  12.710000   3.440741\n",
       "60    14.418950  15.970000   1.551050\n",
       "61     5.914935   4.320000  -1.594934\n",
       "62     7.990755   8.490000   0.499245\n",
       "63    13.591023   5.250000  -8.341023\n",
       "64    23.189775  18.330000  -4.859775\n",
       "65    12.571876  21.719999   9.148123\n",
       "66     5.913659   0.400000  -5.513659\n",
       "67     9.121543   3.700000  -5.421543\n",
       "68    11.491456  15.000000   3.508544\n",
       "69    23.757871  18.000000  -5.757871\n",
       "70     8.911315  29.120001  20.208686\n",
       "71    13.261827  79.300003  66.038176\n",
       "72    33.217764  13.570000 -19.647764"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get results on test dataset\n",
    "def linear_model_predict(coefficients, to_predict):\n",
    "    pred = to_predict.apply(\n",
    "        lambda x: sum(list(map(\n",
    "            lambda k: k[0]*k[1], zip(np.append(x.values[1:], 1), coefficients))))\n",
    "        , axis=1)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "# comparison\n",
    "y_predictions = linear_model_predict(coefs, X_test)\n",
    "comp = y_predictions.to_frame(name='predictions')\n",
    "comp['actual'] = X_test['FIRMCOST']\n",
    "comp['residual'] = comp['actual'] - comp['predictions']\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(comp['predictions'], comp['residual'], 'ro', np.linspace(0, max(comp['predictions']), len(comp)), [0]*len(comp), '--k')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no visible pattern but we have several outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2a68844ac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# density plot\n",
    "import seaborn as sns\n",
    "sns.distplot(comp['residual'], hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016972853550193512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def r_squared(actual, predicted):\n",
    "    mean = sum(actual)/len(actual)\n",
    "    RSS = sum(list(map(lambda x: (x[0] - x[1])**2, zip(predicted, actual))))\n",
    "    TSS = sum(list(map(lambda x: (x - mean)**2, actual)))\n",
    "    \n",
    "    return 1 - RSS/TSS\n",
    "\n",
    "score = r_squared(comp['actual'].tolist(), comp['predictions'].tolist())\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 of the model equals to **0.016**, so the model fits a bit better than a horizontal hyperplane. Due to high correlation between predictors and rank of X is less than p + 1 (5 < 6), so we can assume that ridge regression can be a better choise for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating covariance matrix of $\\tilde{β}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.264688</td>\n",
       "      <td>0.530214</td>\n",
       "      <td>-2.308232</td>\n",
       "      <td>0.044273</td>\n",
       "      <td>-0.052752</td>\n",
       "      <td>-4.163613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.530214</td>\n",
       "      <td>12.687781</td>\n",
       "      <td>0.411645</td>\n",
       "      <td>1.493031</td>\n",
       "      <td>0.760806</td>\n",
       "      <td>-125.394404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.308232</td>\n",
       "      <td>0.411645</td>\n",
       "      <td>150.220666</td>\n",
       "      <td>5.600334</td>\n",
       "      <td>-1.571776</td>\n",
       "      <td>-41.155763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044273</td>\n",
       "      <td>1.493031</td>\n",
       "      <td>5.600334</td>\n",
       "      <td>6.343226</td>\n",
       "      <td>-0.295370</td>\n",
       "      <td>-22.117418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.052752</td>\n",
       "      <td>0.760806</td>\n",
       "      <td>-1.571776</td>\n",
       "      <td>-0.295370</td>\n",
       "      <td>0.333641</td>\n",
       "      <td>-11.916516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.163613</td>\n",
       "      <td>-125.394404</td>\n",
       "      <td>-41.155763</td>\n",
       "      <td>-22.117418</td>\n",
       "      <td>-11.916516</td>\n",
       "      <td>1367.329784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1           2          3          4            5\n",
       "0  1.264688    0.530214   -2.308232   0.044273  -0.052752    -4.163613\n",
       "1  0.530214   12.687781    0.411645   1.493031   0.760806  -125.394404\n",
       "2 -2.308232    0.411645  150.220666   5.600334  -1.571776   -41.155763\n",
       "3  0.044273    1.493031    5.600334   6.343226  -0.295370   -22.117418\n",
       "4 -0.052752    0.760806   -1.571776  -0.295370   0.333641   -11.916516\n",
       "5 -4.163613 -125.394404  -41.155763 -22.117418 -11.916516  1367.329784"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance of β\n",
    "score = r_squared(comp['actual'].tolist(), comp['predictions'].tolist())\n",
    "X = X_train.copy()\n",
    "X['INTERCEPT'] = pd.Series(1, index=X.index)\n",
    "y = X['FIRMCOST'].values\n",
    "X = X.loc[:, 'ASSUME':'INTERCEPT'].values\n",
    "H = np.dot(np.dot(X, np.linalg.inv(np.dot(X.transpose(), X))), X.transpose())\n",
    "# estimating σ^2\n",
    "sigma2 = np.dot(np.dot(y.transpose(), (np.identity(H.shape[0]) - H)), y)/(X.shape[0] - X.shape[1])\n",
    "var = np.dot(np.linalg.inv(np.dot(X.transpose(), X)), sigma2)\n",
    "pd.DataFrame(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016972853550185962"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def fit_ridge_regression(x, y, alpha=1):\n",
    "    X = x.copy()\n",
    "    X = np.array([np.append(step, 1) for step in X])\n",
    "\n",
    "    return np.dot(np.dot(np.linalg.inv((np.dot(X.transpose(), X) + \n",
    "                  np.dot(alpha, np.identity(X.shape[1])))), \n",
    "                                            X.transpose()), y)\n",
    "\n",
    "def ridge_reg_predict(coefficients, to_predict):\n",
    "    pred = to_predict.apply(\n",
    "        lambda x: sum(list(map(\n",
    "            lambda k: k[0]*k[1], zip(np.append(x.values, 1), coefficients))))\n",
    "        , axis=1)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "# Standarize data\n",
    "scaler = StandardScaler()\n",
    "X_train_rg, y_train = X_train.loc[:, 'ASSUME':'SOPH'].values, X_train['FIRMCOST'].values\n",
    "X_train_std = scaler.fit_transform(X_train_rg)\n",
    "\n",
    "# getting most sutable alpha\n",
    "alphas, output = np.linspace(0, 10, 1000), []\n",
    "for alpha in alphas:\n",
    "    ridge_coefs = fit_ridge_regression(X_train_std, y_train, alpha=alpha)\n",
    "    ridge_pred = ridge_reg_predict(ridge_coefs, pd.DataFrame(X_train_std))\n",
    "    output.append(r_squared(y_train, ridge_pred))\n",
    "\n",
    "best_alpha = alphas[output.index(max(output))]\n",
    "ridge_coefs = fit_ridge_regression(X_train_std, y_train, alpha=best_alpha)\n",
    "ridge_pred = ridge_reg_predict(ridge_coefs, pd.DataFrame(scaler.transform(X_test.loc[:, 'ASSUME':'SOPH'].values)))\n",
    "y_test = X_test['FIRMCOST'].values\n",
    "r_squared(y_test, ridge_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2$ score of ridge regression is the same as $R^2$ of pure linear model. Due to most sutable alpha, which is __0.0__. So, ridge regression doesn't improve perfomance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Principal Component Analysis to reduce dimension of the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~dratarov/0 or inside your plot.ly account where it is named 'selecting-principal-components'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~dratarov/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train, y_train = X_train.loc[:, 'ASSUME':'SOPH'].values, X_train['FIRMCOST'].values\n",
    "x_test, y_test = X_test.loc[:, 'ASSUME':'SOPH'].values, X_test['FIRMCOST'].values\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# rescale our data\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# getting mean vector\n",
    "mean_vec = np.mean(x_train, axis=0)\n",
    "# build covariance matrix\n",
    "cov_mat = np.dot((x_train - mean_vec).transpose(), (x_train - mean_vec))/(x_train.shape[0] - 1)\n",
    "# getting eigen values and corresponding vectors\n",
    "eigen_values, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "eigen_pairs = [(np.abs(eigen_values[i]), eigen_vecs[:,i]) for i in range(len(eigen_values))]\n",
    "eigen_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# compute variance explained by each principal component\n",
    "var_exp = [val/sum(eigen_values)*100 for val in sorted(eigen_values, reverse=True)]\n",
    "# cumulative sum of the elements\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "# creat plot\n",
    "trace1 = dict(\n",
    "    type='bar',\n",
    "    x=['PC{}'.format(i) for i in range(1, len(eigen_values) + 1)],\n",
    "    y=var_exp,\n",
    "    name='Individual'\n",
    ")\n",
    "\n",
    "trace2 = dict(\n",
    "    type='scatter',\n",
    "    x=['PC{}'.format(i) for i in range(1, len(eigen_values) + 1)],\n",
    "    y=cum_var_exp,\n",
    "    name='Cumulative'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "\n",
    "layout=dict(\n",
    "    title='Explained variance by different principal components',\n",
    "    yaxis=dict(\n",
    "        title='Explained variance in percent'\n",
    "    ),\n",
    "    annotations=list([\n",
    "        dict(\n",
    "            x=1.16,\n",
    "            y=1.05,\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            text='Explained Variance',\n",
    "            showarrow=False,\n",
    "        )\n",
    "    ])\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='selecting-principal-components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection onto the new Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning:\n",
      "\n",
      "arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.24806993048618198"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reducing the 5-dimensional feature space to a 4-dimensional feature subspace\n",
    "# constructing of the projection matrix\n",
    "def choose_n_comp(N):\n",
    "    return np.hstack((eigen_pairs[i][1].reshape(len(eigen_values),1) for i in range(N)))\n",
    "\n",
    "num_of_comp = 4\n",
    "matrix_w = choose_n_comp(num_of_comp)\n",
    "# transform our samples\n",
    "x_train_tr = np.dot(x_train, matrix_w)\n",
    "x_test_tr = np.dot(x_test, matrix_w)\n",
    "\n",
    "# train linear model\n",
    "coefs = fit_ridge_regression(x_train_tr, y_train, alpha=0)\n",
    "pred = ridge_reg_predict(coefs, pd.DataFrame(x_test_tr))\n",
    "r_squared(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1__ component, __36%__ of variance explained, $R^2$ on linear model = __0.027__ <br>\n",
    "__2__ components, __60%__ of variance explained, $R^2$ on linear model = __-1.190__ <br>\n",
    "__3__ components, __76%__ of variance explained, $R^2$ on linear model = __-0.091__ <br>\n",
    "__4__ components, __90%__ of variance explained, $R^2$ on linear model = __-0.248__ <br>\n",
    "__5__ components, __100%__ of variance explained, $R^2$ on linear model = __0.0169__ <br>\n",
    "\n",
    "So, optimal number of components is still 5. Better performace result with only one component we can consider as luck due to lack of samples in our dataset and impossibility to obtain balanced decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Selection\n",
    "### CRITERION-BASED PROCEDURE (Adjusted $R^2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.15736845008248512, (1, 3)],\n",
       " [0.13107789420863258, (1, 4)],\n",
       " [0.08440232852963192, (1, 3, 4)],\n",
       " [0.005256447227352745, (1, 2)],\n",
       " [-0.007745722688474066, (1, 2, 4)],\n",
       " [-0.02716435251750382, (1, 2, 3)],\n",
       " [-0.043712671980775, (1, 2, 3, 4)],\n",
       " [-0.08724039547125595, (0, 1, 2)],\n",
       " [-0.11427456702110295, (3, 4)],\n",
       " [-0.12351984229840496, (0, 1, 2, 4)],\n",
       " [-0.12465931938912012, (0, 1, 2, 3)],\n",
       " [-0.14968273946623256, (2, 3)],\n",
       " [-0.15524864967324192, (2, 4)],\n",
       " [-0.16506921060718693, (0, 1, 2, 3, 4)],\n",
       " [-0.1926115478503685, (2, 3, 4)],\n",
       " [-0.24696417611594135, (0, 2)],\n",
       " [-0.2816119797516208, (0, 1)],\n",
       " [-0.28567329009918163, (0, 2, 3)],\n",
       " [-0.3057600918280441, (0, 2, 4)],\n",
       " [-0.3205340505498979, (0, 1, 4)],\n",
       " [-0.33569006539354174, (0, 1, 3)],\n",
       " [-0.34885986079418907, (0, 2, 3, 4)],\n",
       " [-0.371973947569995, (0, 1, 3, 4)],\n",
       " [-0.5136209732785726, (0, 4)],\n",
       " [-0.5912135704717056, (0, 3, 4)],\n",
       " [-0.6474805992304404, (0, 3)]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# adjusted r2\n",
    "def adj_r_squared(actual, predicted, exp_var):\n",
    "    r2 = r_squared(actual, predicted)\n",
    "    return 1 - (1 - r2)*(len(actual) - 1)/(len(actual) - exp_var - 1)\n",
    "\n",
    "combinations = []\n",
    "\n",
    "#Looping over k = 1 to k = 5 components in X\n",
    "for k in range(2, x_train.shape[1] + 1):\n",
    "    #Looping over all possible combinations\n",
    "    for indices in itertools.combinations(range(len(x_train.transpose())), k):\n",
    "        combo = np.array([x_train.transpose()[i] for i in indices]).transpose()\n",
    "        reg_coefs = fit_ridge_regression(combo, y_train, alpha=0) \n",
    "        pred = ridge_reg_predict(reg_coefs, pd.DataFrame(np.array([x_test.transpose()[i] for i in indices]).transpose()))\n",
    "        combinations.append([adj_r_squared(y_test, pred, k), indices])   \n",
    "\n",
    "# sort combinations list by adjusted r2 in descending order\n",
    "combinations = sorted(combinations, key=lambda x: x[0], reverse=True)\n",
    "combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, best adjusted $R^2$ score we get when using __SIZELOG__ and __CENTRAL__ components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2100329219523298"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = combinations[0][1]\n",
    "reg_coefs = fit_ridge_regression(np.array([x_train[:, i] for i in best]).transpose(), y_train, alpha=0) \n",
    "pred = ridge_reg_predict(reg_coefs, pd.DataFrame(np.array([x_test[:, i] for i in best]).transpose()))\n",
    "r_squared(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2$ score = __0.21__ for  __SIZELOG__ and __CENTRAL__ features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform F-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7675408272236814"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_test(full, reduced, actual, dff, dfr):\n",
    "    SSE_F = sum([(yi - yi_pred)**2 for yi, yi_pred in zip(actual, full)])\n",
    "    SSE_R = sum([(yi - yi_pred)**2 for yi, yi_pred in zip(actual, reduced)])\n",
    "    F_stat = ((SSE_R - SSE_F)/(dfr - dff))/(SSE_F/dff)\n",
    "\n",
    "    return F_stat\n",
    "\n",
    "def p_value()\n",
    "# F-test between model with all 5 features and model with 2 features \n",
    "dff, dfr = len(comp['actual'].values) - 5 - 1, len(comp['actual'].values) - 2 - 1\n",
    "F_stat = f_test(comp['predictions'].values, pred, comp['actual'].values, dff, dfr)\n",
    "F_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as we can see, we can't reject the null hypothesis. Which tell us that model with 2 components is better choise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.918697454735734"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F-test between model with 2 features and null hypothesis  \n",
    "mean = sum(comp['actual'].values)/len(comp['actual'].values)\n",
    "F_stat_null = f_test(pred, [mean]*40, comp['actual'].values, 37, 39)\n",
    "F_stat_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But here, comparing with table value, we reject null hypothesis and confirm that model with two components performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we choose linear model with __SIZELOG__ and __CENTRAL__ features and formula __y = sizelog*(-2.45) + central*(-1.27) + 10.21__. $R^2$ is 0.21, which is not really good, but is the best choise among other linear models based on our research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
